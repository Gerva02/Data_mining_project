plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="yellow",type = "p")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="yellow",type = "p", pch = 13, bg = "grey")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="yellow",type = "p", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "p", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "g", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "d", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "c", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "b", pch = 13, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "b", pch = 130, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "b", pch = 99, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange",type = "b", pch = 1, bg = "orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1))
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
#abline(v=which.max(knn.pred.k),h=max(knn.pred.k))
#abline ha senso se cambiamo "type="
abline(h=max(knn.pred.k),col="purple")
points(which.max(knn.pred.k),max(knn.pred.k),col="orange")
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass[,-ncol(glass)]
labels<-as.factor(as.matrix(norm_glass[,ncol(glass)])) #non chiedere perchè...
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
library(class)
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))
ggcorrplot(cor(glass%>%
select(-Type)), lab = T , type = "lower" )
#questo bar plot è riguardo freq relative
glass %>%
ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) +
geom_bar()
#questo bar plot è riguardo freq assolute
glass %>%
ggplot(aes(x= Type, y = after_stat(count), fill = Type)) +
geom_bar()
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
gather(key = Measure, value = value, -Type )  %>%
ggplot(aes(x = Type, y= value, color = Measure)) +
geom_violin(trim = F)+
geom_boxplot(width=0.1) +
facet_wrap( ~ Measure ,scales = "free", ncol =2)
glass %>%
filter(Type == "6")
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----
# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
for (j in levels(glass$Type)){
pvalue_shapiro[i,j]<-
shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
# pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
}
}
pvalue_shapiro["Ca", "6" ] <- pvalue_shapiro["K", "6" ] <- pvalue_shapiro["Fe", "6" ] <- NA
round(pvalue_shapiro, 5)
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.7) {
id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
train <- D1[id,]
test <- D1[-id,]
out <- list(train = train, test = test)
}
#Qua abbiamo diviso magari dobbiamo normalizzare
set.seed(123)
glass.train <- dataset_division(glass)$train
glass.test <- dataset_division(glass)$test
#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziam
set.seed(123)
tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
mean(tree.pred == glass.test$Type)
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type)
plot(best.tree); text(best.tree,,pretty=0)
normalize <- function(x, v = NA) {
if (is.na(v)){
return((x - min(x)) / (max(x) - min(x)))
}
else{
return((x - v[1]) / (v[2] -v[1]))
}
}
set.seed(123)
norm_glass <- glass.train
min_max_matrix <- matrix(rep(NA, 18), nrow= 2 , ncol = (ncol(glass)-1) )
for (i in 1: (ncol(glass)-1)){
min_max_matrix[1 , i] <- min(norm_glass %>% pull(i))
min_max_matrix[2 , i] <- max(norm_glass %>% pull(i))
norm_glass[,i] <- normalize(norm_glass %>% pull(i))
}
norm_glass_test<-apply(glass.test %>% select(-Type), MARGIN = 2, normalize)
norm_glass
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass %>% select(-Type)
labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=which.max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
#esiste anche knn.cv !!!!!!!!!
Kmax<-20
knn.pred.k<-rep(0,Kmax)
X_train<-norm_glass %>% select(-Type)
labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla
X_test<-norm_glass_test
for (i in 1:Kmax){
set.seed(42)
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
?apply
?apply
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:,])
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:])
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:,])
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_max_min)
return(list(train_norm=train_norm,test_norm=test_norm))
}
normalize_2(glass.train,glass.test)
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_max_min)
return(list(train_norm=train_norm,test_norm=test_norm))
}
normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
#non ho runnato, devo andare a cena (incrociamo le dita)
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
out$train_norm[1:10,]
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
func<-function(v){
return((v-v[1])/(v[2]-v[1]))
}
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func)
return(data_norm[3:nrow(data_norm),])
}
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max))
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
glass
glass
?sample
