labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
k<-10
out<-normalize(glass.train[,-k],glass.test[,-k])
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
k<-10
out<-normalize(glass.train[,-k],glass.test[,-k])
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
k<-10
out<-normalize(glass.train[,-k],glass.test[,-k])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
out<-normalize(glass.train[,-10],glass.test[,-10])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
out<-normalize(glass.train[,-10],glass.test[,-10])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
out<-normalize(glass.train[,-10],glass.test[,-10])
set.seed(123)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
out<-normalize(glass.train[,-10],glass.test[,-10])
set.seed(101)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels<-glass.train$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-20
#out<-normalize(glass.train[,-k],glass.test[,-k])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- glass.train[,-10]
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<- glass.test[,-10]
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-30
#out<-normalize(glass.train[,-k],glass.test[,-k])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- glass.train[,-10]
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<- glass.test[,-10]
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
Kmax<-40
#out<-normalize(glass.train[,-k],glass.test[,-k])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- glass.train[,-10]
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<- glass.test[,-10]
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
max(knn.pred.k)
Kmax<-40
out<-normalize(glass.train[,-k],glass.test[,-k])
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
#coi dati normalizzati andrà meglio? >>>>0.65 (non normalizzati) >>>>
Kmax<-40
out<-normalize(glass.train[,-k],glass.test[,-k])
knn.pred.k<-rep(0,Kmax)
X_train<- out$train_norm
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<- out$test_norm
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
#coi dati normalizzati andrà meglio? >>>>0.65 (non normalizzati) >>>>
Kmax<-40
#non si normalizza perchè fa già mahalanobis????
knn.pred.k<-rep(0,Kmax)
X_train<-glass.train[,-10]
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<-glass.test[,-10]
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
#coi dati normalizzati andrà meglio? >>>>0.65 (non normalizzati) >>>> 0.58
Kmax<-40
#non si normalizza perchè fa già mahalanobis????
set.seed(47)
knn.pred.k<-rep(0,Kmax)
X_train<-glass.train[,-10]
labels.train<-glass.train$Type
labels.test<-glass.test$Type
X_test<-glass.test[,-10]
for (i in 1:Kmax){
knn.pred.k[i]<-knn_mahalanobis(X_train, X_test, labels.train, labels.test, k=i)
}
r<-rep("black",Kmax)
r[which.max(knn.pred.k)]<-"red"
plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
abline(h=max(knn.pred.k),col="purple")
#coi dati normalizzati andrà meglio? >>>>0.65 (non normalizzati) >>>> 0.58
cv<-5
p<-1-1/cv
n.train<-nrow(glass.train)
k.train <-ncol(glass.train)
labels.train <-glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
knn.mahalanobis.max<-40
mat<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max+knn.mahalanobis.max),ncol=cv+2))
mat[1:knn.kmax,1]<-"knn"
mat[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),1]<-"knn.maha"
mat[1:knn.kmax,2]<-1:knn.kmax
mat[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
mat[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),2]<- 1:knn.mahalanobis.max
set.seed(47)
group <- rep(c(1:cv), round(n.train/cv))
random.assign <- sample( c(1:cv),size = n.train - length(group)) # ne mancheranno sempre cv o meno quindi non ci serve replace
split<-sample( append(group, random.assign) , size=n.train)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out.norm.cv<-normalize(glass.train[split != j  ,-k.train] ,glass.train[split ==j ,-k.train])
train.cv<-out.norm.cv$train_norm
test.cv<-out.norm.cv$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train.cv, test=test.cv, cl=labels.train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat[i,j+2]<-mean(knn.pred == labels.train[split ==j])
}
train.cv.tree <- glass.train[split != j,]
test.cv.tree  <-glass.train[split ==j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (l in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method = "misclass", k = pruned.tree.k[l+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-k.train] , type = "class")
mat[knn.kmax+l,j+2]<- mean(tree.pred == labels.train[split ==j])
}
train.maha <- glass.train[split != j,]
test.maha <-glass.train[split ==j,]
#metodo knn maha
for (h in 1:knn.mahalanobis.max){
mat[knn.kmax+tree.size.max+h,j+2]<- knn_mahalanobis(train.maha[,-k.train], test.maha[,-k.train], train.maha$Type, test.maha$Type, k=h)
}
}
res<-cbind(mat[,c(1,2)],apply(mat[,3:j+2],MARGIN=1,mean))
colnames(res)<-c("metodo","hyperparameter","accuracy")
res<-as.tibble(res)
best.res<-rbind(res%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)),
res%>%filter(metodo=="knn.maha")%>%filter(accuracy==max(accuracy)))
best.res
res %>%
ggplot(mapping  = aes(x = hyperparameter, y= accuracy, color=metodo))  +
geom_line()+
geom_point()+
facet_grid(~metodo) +
labs(title= "Variazione di Accuracy Rispetto a Iperparametri")
res
cv<-5
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels.train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
knn.mahalanobis.max<-40
mat.2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max+knn.mahalanobis.max),ncol=cv+2))
mat.2[1:knn.kmax,1]<-"knn"
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),1]<-"knn.maha"
mat.2[1:knn.kmax,2]<-1:knn.kmax
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),2]<- 1:knn.mahalanobis.max
set.seed(47)
group <- rep(c(1:cv), round(n.train/cv))
random.assign <- sample( c(1:cv),size = n.train - length(group)) # ne mancheranno sempre cv o meno quindi non ci serve replace
split<-sample( append(group, random.assign) , size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out.norm.cv.2<-normalize(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train.cv<-out.norm.cv.2$train_norm
test.cv<-out.norm.cv.2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train.cv, test=test.cv, cl=labels.train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat.2[i,j+2]<-mean(knn.pred == labels.train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,] #ho provato con quelli normalizzati ma non cambia nulla
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (l in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method = "misclass", k = pruned.tree.k[l+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-k.train] , type = "class")
mat.2[knn.kmax+l,j+2]<- mean(tree.pred == labels.train[split ==j])
}
train.maha <- transformed.glass.train[split != j,]
test.maha <-transformed.glass.train[split ==j,]
#metodo knn maha
for (h in 1:knn.mahalanobis.max){
mat.2[knn.kmax+tree.size.max+h,j+2]<- knn_mahalanobis(train.maha[,-k.train], test.maha[,-k.train], train.maha$Type, test.maha$Type, k=h)
}
}
res.2<-cbind(mat.2[,c(1,2)],apply(mat.2[,3:j+2],MARGIN=1,mean))
colnames(res.2)<-c("metodo","hyperparameter","accuracy")
res.2<-as.tibble(res.2)
best.res.2<-rbind(res.2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)))
best.res.2
best.res.2
cv<-5
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels.train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
knn.mahalanobis.max<-40
mat.2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max+knn.mahalanobis.max),ncol=cv+2))
mat.2[1:knn.kmax,1]<-"knn"
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),1]<-"knn.maha"
mat.2[1:knn.kmax,2]<-1:knn.kmax
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),2]<- 1:knn.mahalanobis.max
set.seed(47)
group <- rep(c(1:cv), round(n.train/cv))
random.assign <- sample( c(1:cv),size = n.train - length(group)) # ne mancheranno sempre cv o meno quindi non ci serve replace
split<-sample( append(group, random.assign) , size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out.norm.cv.2<-normalize(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train.cv<-out.norm.cv.2$train_norm
test.cv<-out.norm.cv.2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train.cv, test=test.cv, cl=labels.train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat.2[i,j+2]<-mean(knn.pred == labels.train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,] #ho provato con quelli normalizzati ma non cambia nulla
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (l in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method = "misclass", k = pruned.tree.k[l+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-k.train] , type = "class")
mat.2[knn.kmax+l,j+2]<- mean(tree.pred == labels.train[split ==j])
}
train.maha <- transformed.glass.train[split != j,]
test.maha <-transformed.glass.train[split ==j,]
#metodo knn maha
for (h in 1:knn.mahalanobis.max){
mat.2[knn.kmax+tree.size.max+h,j+2]<- knn_mahalanobis(train.maha[,-k.train], test.maha[,-k.train], train.maha$Type, test.maha$Type, k=h)
}
}
res.2<-cbind(mat.2[,c(1,2)],apply(mat.2[,3:j+2],MARGIN=1,mean))
colnames(res.2)<-c("metodo","hyperparameter","accuracy")
res.2<-as.tibble(res.2)
best.res.2<-rbind(res.2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="knn.maha")%>%filter(accuracy==max(accuracy)))
best.res.2
res.2 %>%
ggplot(mapping  = aes(x = hyperparameter, y= accuracy, color=metodo))  +
geom_line()+
geom_point()+
facet_grid(~metodo) +
labs(title= "Variazione di Accuracy Rispetto a Iperparametri") #DA CAMBIARE IL TITOLO....
cv<-5
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels.train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
knn.mahalanobis.max<-40
mat.2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max+knn.mahalanobis.max),ncol=cv+2))
mat.2[1:knn.kmax,1]<-"knn"
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),1]<-"knn.maha"
mat.2[1:knn.kmax,2]<-1:knn.kmax
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),2]<- 1:knn.mahalanobis.max
group <- rep(c(1:cv), round(n.train/cv))
random.assign <- sample( c(1:cv),size = n.train - length(group)) # ne mancheranno sempre cv o meno quindi non ci serve replace
split<-sample( append(group, random.assign) , size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out.norm.cv.2<-normalize(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train.cv<-out.norm.cv.2$train_norm
test.cv<-out.norm.cv.2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train.cv, test=test.cv, cl=labels.train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat.2[i,j+2]<-mean(knn.pred == labels.train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,] #ho provato con quelli normalizzati ma non cambia nulla
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (l in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method = "misclass", k = pruned.tree.k[l+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-k.train] , type = "class")
mat.2[knn.kmax+l,j+2]<- mean(tree.pred == labels.train[split ==j])
}
train.maha <- transformed.glass.train[split != j,]
test.maha <-transformed.glass.train[split ==j,]
#metodo knn maha
for (h in 1:knn.mahalanobis.max){
mat.2[knn.kmax+tree.size.max+h,j+2]<- knn_mahalanobis(train.maha[,-k.train], test.maha[,-k.train], train.maha$Type, test.maha$Type, k=h)
}
}
res.2<-cbind(mat.2[,c(1,2)],apply(mat.2[,3:j+2],MARGIN=1,mean))
colnames(res.2)<-c("metodo","hyperparameter","accuracy")
res.2<-as.tibble(res.2)
best.res.2<-rbind(res.2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="knn.maha")%>%filter(accuracy==max(accuracy)))
best.res.2
cv<-5
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels.train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
knn.mahalanobis.max<-40
mat.2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max+knn.mahalanobis.max),ncol=cv+2))
mat.2[1:knn.kmax,1]<-"knn"
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),1]<-"knn.maha"
mat.2[1:knn.kmax,2]<-1:knn.kmax
mat.2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
mat.2[(knn.kmax+tree.size.max+1):(knn.kmax+tree.size.max+knn.mahalanobis.max),2]<- 1:knn.mahalanobis.max
set.seed(47)
group <- rep(c(1:cv), round(n.train/cv))
random.assign <- sample( c(1:cv),size = n.train - length(group)) # ne mancheranno sempre cv o meno quindi non ci serve replace
split<-sample( append(group, random.assign) , size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out.norm.cv.2<-normalize(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train.cv<-out.norm.cv.2$train_norm
test.cv<-out.norm.cv.2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train.cv, test=test.cv, cl=labels.train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat.2[i,j+2]<-mean(knn.pred == labels.train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,] #ho provato con quelli normalizzati ma non cambia nulla
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (l in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method = "misclass", k = pruned.tree.k[l+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-k.train] , type = "class")
mat.2[knn.kmax+l,j+2]<- mean(tree.pred == labels.train[split ==j])
}
train.maha <- transformed.glass.train[split != j,]
test.maha <-transformed.glass.train[split ==j,]
#metodo knn maha
for (h in 1:knn.mahalanobis.max){
mat.2[knn.kmax+tree.size.max+h,j+2]<- knn_mahalanobis(train.maha[,-k.train], test.maha[,-k.train], train.maha$Type, test.maha$Type, k=h)
}
}
res.2<-cbind(mat.2[,c(1,2)],apply(mat.2[,3:j+2],MARGIN=1,mean))
colnames(res.2)<-c("metodo","hyperparameter","accuracy")
res.2<-as.tibble(res.2)
best.res.2<-rbind(res.2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)),
res.2%>%filter(metodo=="knn.maha")%>%filter(accuracy==max(accuracy)))
best.res.2
res.2 %>%
ggplot(mapping  = aes(x = hyperparameter, y= accuracy, color=metodo))  +
geom_line()+
geom_point()+
facet_grid(~metodo) +
labs(title= "Variazione di Accuracy Rispetto a Iperparametri") #DA CAMBIARE IL TITOLO....
