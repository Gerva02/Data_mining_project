res %>%
ggplot(mapping  = aes(x = hyperparameter, y= accuracy, color=metodo))  +
geom_line()+
geom_point()+
facet_grid(~metodo) +
labs(title= "Variazione di Accuracy Rispetto a Iperparametri")
out_norm<- normalize_2(glass.train[,-k.train],glass.test[,-k.train]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
set.seed(123)
knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #non funziona se ci escono 2 o più soluzioni
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = best.res %>% filter(metodo=="tree") %>% pull(hyperparameter) )
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
glass.train
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 0.6666667 )
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
#BISOGNA RIVEDERE UN PO TUTA LA QUESTIONE cv E PERCENTUALE NEL TEST SET (O RIMETTIAMO cv=5 E perc=0.7 CHE COMUNQUE PER POCHI RECORD
#HA SENSO E CI VIENE UN OUTPUT CARINO...PERò CON COSì TANTI DATI NEL TEST SET TEMO SI SOVRASTIMI LA PRECISIONE (MINOR BIAS A FRONTE DI MAGGIOR VARIANZA CHE HA SENSO CAMBIANDO IL seed OTTENIAMO VALORI SBALLATI...) -> quel poco che sono riuscito a capire mi sembra sbagliato prova a mandare un audio
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 0)
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
#BISOGNA RIVEDERE UN PO TUTA LA QUESTIONE cv E PERCENTUALE NEL TEST SET (O RIMETTIAMO cv=5 E perc=0.7 CHE COMUNQUE PER POCHI RECORD
#HA SENSO E CI VIENE UN OUTPUT CARINO...PERò CON COSì TANTI DATI NEL TEST SET TEMO SI SOVRASTIMI LA PRECISIONE (MINOR BIAS A FRONTE DI MAGGIOR VARIANZA CHE HA SENSO CAMBIANDO IL seed OTTENIAMO VALORI SBALLATI...) -> quel poco che sono riuscito a capire mi sembra sbagliato prova a mandare un audio
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = glass.train)
pred<-predict(mod,glass.test[,-k])
pred
mean(pred==glass.test$Type) #FENOMENALE (DA RIVEDERE)
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = transformed.glass.train)
pred<-predict(mod,transformed.glass.test[,-7])
pred
mean(pred==transformed.glass.test$Type) #FENOMENALE (DA RIVEDERE)
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = glass.train)
pred<-predict(mod, glass.test[,-7])
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = glass.train)
pred<-predict(mod, glass.test[,-10])
pred
mean(pred==glass.test$Type) #FENOMENALE (DA RIVEDERE)
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,]
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
pruned.tree.k
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.glass.cv
pruned.tree.k
k= pruned.tree.k[i+1]
k<-ncol(glass)
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,]
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= 3 )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
mat_2
pruned.tree
predict(pruned.tree , test.cv.tree[,-7] , type = "class")
pruned.tree
test.cv.tree
tree.glass.cv
train.cv.tree
tree.glass.cv
tree.glass.cv <- tree(Type ~. , train.cv.tree)
train.cv.tree
tree(Type ~. , train.cv.tree)
transformed.glass.train[split != j,]
glass.train[split != j,]
transformed.glass.train
library(car)
p <-glass.train %>%
select( -c("Fe", "K" , "Ba", "Type"))
p.test <-glass.test %>%
select( -c("Fe", "K" , "Ba", "Type"))
p1 <- p %>%
apply(MARGIN =2 , FUN = powerTransform, family = "bcnPower")
a3 <- as.vector(c( p1$RI[1]$lambda,p1$Na[1]$lambda , p1$Mg[1]$lambda, p1$Al[1]$lambda, p1$Si[1]$lambda,p1$Ca[1]$lambda))
colnames(p)
col
transformedY <- bcPower(with(p, cbind(RI, Na, Mg, Al, Si, Ca)),
lambda = a3 ,gamma= 0.01)
transformedY.test <- bcPower(with(p.test, cbind(RI, Na, Mg, Al, Si, Ca)),
lambda = a3 ,gamma= 0.01)
transformed.glass.train <- tibble(cbind(as.data.frame(transformedY)), Type = glass.train$Type)
colnames(transformed.glass.train)<-c("RI_new","Na_new","Mg_new","Al_new","Si_new","Ca_new","Type")
transformed.glass.test <- tibble(cbind(as.data.frame(transformedY.test)), Type = glass.test$Type)
colnames(transformed.glass.test)<-c("RI_new","Na_new","Mg_new","Al_new","Si_new","Ca_new","Type")
transformed.glass.train%>%
gather(key = Measure, value = valore, -Type )  %>%
ggplot(aes(x= valore , colour= Type)) +
geom_density() +
facet_wrap(~Measure, scales= "free")
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,]
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
res_2<-cbind(mat_2[,c(1,2)],apply(mat_2[,3:j+2],MARGIN=1,mean)) #possiamo usare median se vogliamo (meglio di no..)
colnames(res_2)<-c("metodo","hyperparameter","accuracy")
res<-as.tibble(res_2)
best.res_2<-rbind(res_2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res_2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)))
best.res_2
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- cbind(train_cv,labels_train[split != j])
test.cv.tree  <- cbind(test_cv,labels_train[split == j])
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- as.data.frame(cbind(train_cv,labels_train[split != j]))
test.cv.tree  <- as.data.frame(cbind(test_cv,labels_train[split == j]))
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
as.data.frame(cbind(test_cv,labels_train[split == j]))
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- as.data.frame(cbind(train_cv,labels_train[split != j]))
colnames(train.cv.tree)[7]<-"Type"
test.cv.tree  <- as.data.frame(cbind(test_cv,labels_train[split == j]))
colnames(test.cv.tree)[7]<-"Type"
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
train.cv.tree
prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- as.data.frame(cbind(train_cv,labels_train[split != j]))
colnames(train.cv.tree)[7]<-"Type"
train.cv.tree[,7]<-as.factor(train.cv.tree[,7])
test.cv.tree  <- as.data.frame(cbind(test_cv,labels_train[split == j]))
colnames(test.cv.tree)[7]<-"Type"
test.cv.tree[,7]<-as.factor(test.cv.tree[,7])
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mean(tree.pred == labels_train[split ==j])
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- as.data.frame(cbind(train_cv,labels_train[split != j]))
colnames(train.cv.tree)[7]<-"Type"
train.cv.tree[,7]<-as.factor(train.cv.tree[,7])
levels(train.cv.tree[,7])<-as.factor(1:7)
test.cv.tree  <- as.data.frame(cbind(test_cv,labels_train[split == j]))
colnames(test.cv.tree)[7]<-"Type"
test.cv.tree[,7]<-as.factor(test.cv.tree[,7])
levels(test.cv.tree[,7])<-as.factor(1:7)
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
predict(pruned.tree , test.cv.tree[,-7] , type = "class")
labels_train[split ==j]
set.seed(900) # teniamo questo
cv<-7
p<-1-1/cv
n.train<-nrow(transformed.glass.train)
k.train <-ncol(transformed.glass.train)
labels_train <-transformed.glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat_2<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat_2[1:knn.kmax,1]<-"knn"
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat_2[1:knn.kmax,2]<-1:knn.kmax
mat_2[(knn.kmax+1):(knn.kmax+tree.size.max),2]<- pruned.tree.k[2:(length(pruned.tree.k)-1)]
set.seed(123)
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) #non ha senso questo metodo, capisco avere stessa proporzione ma usiamo una tecnica più flessibile se modifichiamo cv o proporzione train/test all'inizio (30% nel test set mi sembra eccessivo)
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
out_norm_cv_2<-normalize_2(transformed.glass.train[split != j  ,-k.train] ,transformed.glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv_2$train_norm
test_cv<-out_norm_cv_2$test_norm
#metodo knn
for (i in 1:knn.kmax){
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat_2[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- transformed.glass.train[split != j,] #ho provato con quelli normalizzati ma non cambia nulla
test.cv.tree  <-transformed.glass.train[split == j,]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
pruned.tree <-prune.tree(tree.glass.cv ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[,-7] , type = "class")
mat_2[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
res_2<-cbind(mat_2[,c(1,2)],apply(mat_2[,3:j+2],MARGIN=1,mean)) #possiamo usare median se vogliamo (meglio di no..)
colnames(res_2)<-c("metodo","hyperparameter","accuracy")
res<-as.tibble(res_2)
best.res_2<-rbind(res_2%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res_2%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)))
best.res_2
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , transformed.glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 0)
tree.best.pred <-predict(pruned.best.tree  , transformed.glass.test[-7] , type = "class")
mean(transformed.glass.test$Type == tree.best.pred)
#BISOGNA RIVEDERE UN PO TUTA LA QUESTIONE cv E PERCENTUALE NEL TEST SET (O RIMETTIAMO cv=5 E perc=0.7 CHE COMUNQUE PER POCHI RECORD
#HA SENSO E CI VIENE UN OUTPUT CARINO...PERò CON COSì TANTI DATI NEL TEST SET TEMO SI SOVRASTIMI LA PRECISIONE (MINOR BIAS A FRONTE DI MAGGIOR VARIANZA CHE HA SENSO CAMBIANDO IL seed OTTENIAMO VALORI SBALLATI...) -> quel poco che sono riuscito a capire mi sembra sbagliato prova a mandare un audio
out_norm<- normalize_2(transformed.glass.train[,-7],transformed.glass.test[,-7]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #non funziona se ci escono 2 o più soluzioni
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
#senza normalizzare
tree.best.glass <- tree(Type ~. , transformed.glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 0)
tree.best.pred.transf <-predict(pruned.best.tree  , transformed.glass.test[-7] , type = "class")
mean(transformed.glass.test$Type == tree.best.pred.transf)
#BISOGNA RIVEDERE UN PO TUTA LA QUESTIONE cv E PERCENTUALE NEL TEST SET (O RIMETTIAMO cv=5 E perc=0.7 CHE COMUNQUE PER POCHI RECORD
#HA SENSO E CI VIENE UN OUTPUT CARINO...PERò CON COSì TANTI DATI NEL TEST SET TEMO SI SOVRASTIMI LA PRECISIONE (MINOR BIAS A FRONTE DI MAGGIOR VARIANZA CHE HA SENSO CAMBIANDO IL seed OTTENIAMO VALORI SBALLATI...) -> quel poco che sono riuscito a capire mi sembra sbagliato prova a mandare un audio
#senza normalizzare
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 0)
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
#BISOGNA RIVEDERE UN PO TUTA LA QUESTIONE cv E PERCENTUALE NEL TEST SET (O RIMETTIAMO cv=5 E perc=0.7 CHE COMUNQUE PER POCHI RECORD
#HA SENSO E CI VIENE UN OUTPUT CARINO...PERò CON COSì TANTI DATI NEL TEST SET TEMO SI SOVRASTIMI LA PRECISIONE (MINOR BIAS A FRONTE DI MAGGIOR VARIANZA CHE HA SENSO CAMBIANDO IL seed OTTENIAMO VALORI SBALLATI...) -> quel poco che sono riuscito a capire mi sembra sbagliato prova a mandare un audio
out_norm<- normalize_2(transformed.glass.train[,-7],transformed.glass.test[,-7]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
knn.pred.transf <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #non funziona se ci escono 2 o più soluzioni
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
out_norm<- normalize_2(transformed.glass.train[,-7],transformed.glass.test[,-7]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
knn.pred.transf <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #non funziona se ci escono 2 o più soluzioni
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred.transf) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
true<-glass.test$Type
pred_top<-knn.pred.transf
confusionMatrix(pred,true)
out_norm<- normalize_2(transformed.glass.train[,-7],transformed.glass.test[,-7]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
knn.pred.transf <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #non funziona se ci escono 2 o più soluzioni
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred.transf) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
