summary(tree.glass)
#plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
#mean(tree.pred == glass.test$Type)
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type)
plot(best.tree); text(best.tree,,pretty=0)
train_norm<-glass.train
test_norm<-glass.test
tree.best.glass <- tree(Type ~. , glass.train)
pruned.tree.k <-prune.tree(tree.best.glass  ,method="misclass")$k
# #esiste anche knn.cv !!!!!!!!!
# Kmax<-20
# knn.pred.k<-rep(0,Kmax)
# X_train<-norm_glass %>% select(-Type)
# labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla
# X_test<-norm_glass_test
# for (i in 1:Kmax){
#   set.seed(42)
#   knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
#   knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
# }
# r<-rep("black",Kmax)
# r[which.max(knn.pred.k)]<-"red"
# plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
# abline(h=max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
#v è un vettore colonna il primo valore è il minimo il secondo il massimo e il resto solo i valori effettivi delle colonne (Fe, Ba, etc)
#funzione che prende vettore, toglie il primo numero, e lo divide da secondo - primo
func<-function(v){
return((v-v[1])/(v[2]-v[1])) # non aggiorno v[1] v[2] fino alla fine e quelli saranno innutili
}
prova <-c(1,2,rnorm(100))
func(prova) #vediamo v[1] -> 0 v[2]->1
# matrix sarà la nostra tabella min e max
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func) #applichiamo func ad ogni colonna func
return(data_norm[3:nrow(data_norm),]) # da 3 in poi perchè i primi due valori sono inutili
}
# questa funzione prende sia il train che il test e normalizza il test con min e max del train
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max)) #qua salviamo min e max -> matrice che anda in norm aux
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
cv<-5
p<-1-1/cv
n.train<-nrow(glass.train)
k.train <-ncol(glass.train)
labels_train <-glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat[1:knn.kmax,1]<-"knn"
mat[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat[1:knn.kmax,2]<-1:knn.kmax
mat[(knn.kmax+1):(knn.kmax+tree.size.max),2]<-1:tree.size.max
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
split<-sample(rep(c(1:5),n.train/cv), size=n.train) # facciamo così con il rep per evitare gruppi sbilanciati n.train/cv deve fare un numero intero
out_norm_cv<-normalize_2(glass.train[split != j  ,-k.train] ,glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv$train_norm
test_cv<-out_norm_cv$test_norm
#metodo knn
for (i in 1:knn.kmax){
set.seed(123)
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- glass.train[split != j  ,-k.train]
test.cv.tree  <-glass.train[split ==j ,-k.train]
train.cv.tree$Type <-labels_train[split != j]
test.cv.tree$Type <-labels_train[split ==j]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
set.seed(123)
pruned.tree <-prune.tree(tree.glass ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[-10] , type = "class")
mat[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
library(class)
#library(knnGarden)
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))
ggcorrplot(cor(glass%>%
select(-Type)), lab = T , type = "lower" )
#questo bar plot è riguardo freq relative
glass %>%
ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) +
geom_bar()
#questo bar plot è riguardo freq assolute
glass %>%
ggplot(aes(x= Type, y = after_stat(count), fill = Type)) +
geom_bar()
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
gather(key = Measure, value = value, -Type )  %>%
ggplot(aes(x = Type, y= value, color = Measure)) +
geom_violin(trim = F)+
geom_boxplot(width=0.1) +
facet_wrap( ~ Measure ,scales = "free", ncol =2)
#TODO boxplot confronto Ca e RI x la scelta di quella da togliere in knn
glass %>%
filter(Type == "6")
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----
# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
for (j in levels(glass$Type)){
pvalue_shapiro[i,j]<-
shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
# pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
}
}
pvalue_shapiro["Ca", "6" ] <- pvalue_shapiro["K", "6" ] <- pvalue_shapiro["Fe", "6" ] <- NA
round(pvalue_shapiro, 5)
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.7) {
set.seed(42)
id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
train <- D1[id,]
test <- D1[-id,]
out <- list(train = train, test = test)
}
#Qua abbiamo diviso magari dobbiamo normalizzare
set.seed(123)
glass.train <- dataset_division(glass,perc=0.80)$train #non ha senso 30% nel test set se facciamo cv
glass.test <- dataset_division(glass,perc=0.80)$test
#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziam
set.seed(123)
tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
#plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
#mean(tree.pred == glass.test$Type)
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type)
plot(best.tree); text(best.tree,,pretty=0)
train_norm<-glass.train
test_norm<-glass.test
tree.best.glass <- tree(Type ~. , glass.train)
pruned.tree.k <-prune.tree(tree.best.glass  ,method="misclass")$k
# #esiste anche knn.cv !!!!!!!!!
# Kmax<-20
# knn.pred.k<-rep(0,Kmax)
# X_train<-norm_glass %>% select(-Type)
# labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla
# X_test<-norm_glass_test
# for (i in 1:Kmax){
#   set.seed(42)
#   knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
#   knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
# }
# r<-rep("black",Kmax)
# r[which.max(knn.pred.k)]<-"red"
# plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
# abline(h=max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
#v è un vettore colonna il primo valore è il minimo il secondo il massimo e il resto solo i valori effettivi delle colonne (Fe, Ba, etc)
#funzione che prende vettore, toglie il primo numero, e lo divide da secondo - primo
func<-function(v){
return((v-v[1])/(v[2]-v[1])) # non aggiorno v[1] v[2] fino alla fine e quelli saranno innutili
}
prova <-c(1,2,rnorm(100))
func(prova) #vediamo v[1] -> 0 v[2]->1
# matrix sarà la nostra tabella min e max
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func) #applichiamo func ad ogni colonna func
return(data_norm[3:nrow(data_norm),]) # da 3 in poi perchè i primi due valori sono inutili
}
# questa funzione prende sia il train che il test e normalizza il test con min e max del train
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max)) #qua salviamo min e max -> matrice che anda in norm aux
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
cv<-9
p<-1-1/cv
n.train<-nrow(glass.train)
k.train <-ncol(glass.train)
labels_train <-glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat[1:knn.kmax,1]<-"knn"
mat[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat[1:knn.kmax,2]<-1:knn.kmax
mat[(knn.kmax+1):(knn.kmax+tree.size.max),2]<-1:tree.size.max
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) # facciamo così con il rep per evitare gruppi sbilanciati n.train/cv deve fare un numero intero
out_norm_cv<-normalize_2(glass.train[split != j  ,-k.train] ,glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv$train_norm
test_cv<-out_norm_cv$test_norm
#metodo knn
for (i in 1:knn.kmax){
set.seed(123)
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- glass.train[split != j  ,-k.train]
test.cv.tree  <-glass.train[split ==j ,-k.train]
train.cv.tree$Type <-labels_train[split != j]
test.cv.tree$Type <-labels_train[split ==j]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
set.seed(123)
pruned.tree <-prune.tree(tree.glass ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[-10] , type = "class")
mat[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
res<-cbind(mat[,c(1,2)],apply(mat[,3:j+2],MARGIN=1,mean)) #possiamo usare median se vogliamo (meglio di no..)
colnames(res)<-c("metodo","hyperparameter","accuracy")
res<-as.tibble(res)
rbind(res%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)))
out_norm<- normalize_2(glass.train[,-k.train],glass.test[,-k.train]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
set.seed(123)
knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 2) #perchè con k=2 viene meglio e soprattutto cambia col valore del seed?????
#non ha senso che stimiamo k=4 e usiamo K=2....altirmenti era come aver già fatto nella cross-validation
#teniamo da parte il test set apposta perchè non vi siano influenze da parte del train/validation set. quindi se il migliore è con k=4 non ha senso usare k=2.... provo con diversi seed....
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 1 ) #giusto fare =1 perchè è il migliore??? seed da scegliere
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
library(class)
#library(knnGarden)
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))
ggcorrplot(cor(glass%>%
select(-Type)), lab = T , type = "lower" )
#questo bar plot è riguardo freq relative
glass %>%
ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) +
geom_bar()
#questo bar plot è riguardo freq assolute
glass %>%
ggplot(aes(x= Type, y = after_stat(count), fill = Type)) +
geom_bar()
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
gather(key = Measure, value = value, -Type )  %>%
ggplot(aes(x = Type, y= value, color = Measure)) +
geom_violin(trim = F)+
geom_boxplot(width=0.1) +
facet_wrap( ~ Measure ,scales = "free", ncol =2)
#TODO boxplot confronto Ca e RI x la scelta di quella da togliere in knn
glass %>%
filter(Type == "6")
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----
# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
for (j in levels(glass$Type)){
pvalue_shapiro[i,j]<-
shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
# pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
}
}
pvalue_shapiro["Ca", "6" ] <- pvalue_shapiro["K", "6" ] <- pvalue_shapiro["Fe", "6" ] <- NA
round(pvalue_shapiro, 5)
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.7) {
set.seed(42)
id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
train <- D1[id,]
test <- D1[-id,]
out <- list(train = train, test = test)
}
#Qua abbiamo diviso magari dobbiamo normalizzare
set.seed(123)
glass.train <- dataset_division(glass,perc=0.85)$train #non ha senso 30% nel test set se facciamo cv
glass.test <- dataset_division(glass,perc=0.85)$test
#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziam
set.seed(123)
tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
#plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
#mean(tree.pred == glass.test$Type)
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type)
plot(best.tree); text(best.tree,,pretty=0)
train_norm<-glass.train
test_norm<-glass.test
tree.best.glass <- tree(Type ~. , glass.train)
pruned.tree.k <-prune.tree(tree.best.glass  ,method="misclass")$k
# #esiste anche knn.cv !!!!!!!!!
# Kmax<-20
# knn.pred.k<-rep(0,Kmax)
# X_train<-norm_glass %>% select(-Type)
# labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla
# X_test<-norm_glass_test
# for (i in 1:Kmax){
#   set.seed(42)
#   knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
#   knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
# }
# r<-rep("black",Kmax)
# r[which.max(knn.pred.k)]<-"red"
# plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
# abline(h=max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
#v è un vettore colonna il primo valore è il minimo il secondo il massimo e il resto solo i valori effettivi delle colonne (Fe, Ba, etc)
#funzione che prende vettore, toglie il primo numero, e lo divide da secondo - primo
func<-function(v){
return((v-v[1])/(v[2]-v[1])) # non aggiorno v[1] v[2] fino alla fine e quelli saranno innutili
}
prova <-c(1,2,rnorm(100))
func(prova) #vediamo v[1] -> 0 v[2]->1
# matrix sarà la nostra tabella min e max
norm_aux<-function(data,matrix){
data_2<-rbind(matrix,data)
data_norm<-apply(data_2,MARGIN = 2,func) #applichiamo func ad ogni colonna func
return(data_norm[3:nrow(data_norm),]) # da 3 in poi perchè i primi due valori sono inutili
}
# questa funzione prende sia il train che il test e normalizza il test con min e max del train
normalize_2<-function(train,test){
matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max)) #qua salviamo min e max -> matrice che anda in norm aux
train_norm<-norm_aux(train,matrix_min_max)
test_norm<-norm_aux(test,matrix_min_max)
return(list(train_norm=train_norm,test_norm=test_norm))
}
out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
cv<-7
p<-1-1/cv
n.train<-nrow(glass.train)
k.train <-ncol(glass.train)
labels_train <-glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat[1:knn.kmax,1]<-"knn"
mat[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat[1:knn.kmax,2]<-1:knn.kmax
mat[(knn.kmax+1):(knn.kmax+tree.size.max),2]<-1:tree.size.max
#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
split<-sample(rep(c(1:cv),n.train/cv), size=n.train) # facciamo così con il rep per evitare gruppi sbilanciati n.train/cv deve fare un numero intero
out_norm_cv<-normalize_2(glass.train[split != j  ,-k.train] ,glass.train[split ==j ,-k.train])
train_cv<-out_norm_cv$train_norm
test_cv<-out_norm_cv$test_norm
#metodo knn
for (i in 1:knn.kmax){
set.seed(123)
knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
#knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F)
#TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
mat[i,j+2]<-mean(knn.pred == labels_train[split ==j])
}
train.cv.tree <- glass.train[split != j  ,-k.train]
test.cv.tree  <-glass.train[split ==j ,-k.train]
train.cv.tree$Type <-labels_train[split != j]
test.cv.tree$Type <-labels_train[split ==j]
tree.glass.cv <- tree(Type ~. , train.cv.tree)
#metodo alberi
for (i in 1:tree.size.max){
set.seed(123)
pruned.tree <-prune.tree(tree.glass ,method="misclass", k= pruned.tree.k[i+1] )
tree.pred <-predict(pruned.tree , test.cv.tree[-10] , type = "class")
mat[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
}
}
res<-cbind(mat[,c(1,2)],apply(mat[,3:j+2],MARGIN=1,mean)) #possiamo usare median se vogliamo (meglio di no..)
colnames(res)<-c("metodo","hyperparameter","accuracy")
res<-as.tibble(res)
rbind(res%>%filter(metodo=="knn")%>%filter(accuracy==max(accuracy)),
res%>%filter(metodo=="tree")%>%filter(accuracy==max(accuracy)))
out_norm<- normalize_2(glass.train[,-k.train],glass.test[,-k.train]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
set.seed(123)
knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 2) #perchè con k=2 viene meglio e soprattutto cambia col valore del seed?????
#non ha senso che stimiamo k=4 e usiamo K=2....altirmenti era come aver già fatto nella cross-validation
#teniamo da parte il test set apposta perchè non vi siano influenze da parte del train/validation set. quindi se il migliore è con k=4 non ha senso usare k=2.... provo con diversi seed....
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 1 ) #giusto fare =1 perchè è il migliore??? seed da scegliere
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
out_norm<- normalize_2(glass.train[,-k.train],glass.test[,-k.train]) #k è lo stesso in ogni caso dai
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm
set.seed(123)
knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 1) #perchè con k=2 viene meglio e soprattutto cambia col valore del seed?????
#non ha senso che stimiamo k=4 e usiamo K=2....altirmenti era come aver già fatto nella cross-validation
#teniamo da parte il test set apposta perchè non vi siano influenze da parte del train/validation set. quindi se il migliore è con k=4 non ha senso usare k=2.... provo con diversi seed....
#TOCCA SCEGLIERE IL SEED E USIAMO QUEL CHE CI ESCE
mean(glass.test$Type == knn.pred) #molto più alto rispetto al validation...temo che usare solo 214 record è poco...
#senza normalizzare
#qui seed non incide???
tree.best.glass <- tree(Type ~. , glass.train)
pruned.best.tree <-prune.tree(tree.best.glass  ,method="misclass", k = 1 ) #giusto fare =1 perchè è il migliore??? seed da scegliere
tree.best.pred <-predict(pruned.best.tree  , glass.test[-10] , type = "class")
mean(glass.test$Type == tree.best.pred)
mod<-glm(formula = Type~.,data = glass.train,family = binomial)
mod
mod<-glm(formula = Type~.,data = glass.train,family = binomial)
pred<-predict(mod,glass.test[,-k])
n<-nrow(glass)
k<-ncol(glass)
pred<-predict(mod,glass.test[,-k])
pred
?glm
mod<-glm(formula = Type~.,data = glass.train,family = binomial,weights = NULL)
pred<-predict(mod,glass.test[,-k])
pred
?glm
#mi sa che sta cosa me la sono inventata...
mod<-glm.fit(formula = Type~.,data = glass.train,family = binomial,weights = NULL)
#mi sa che sta cosa me la sono inventata...
mod<-glm.fit(formula = Type~.,data = glass.train,family = binomial)
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = glass.train)
library(nnet)
#mi sa che sta cosa me la sono inventata...
mod<-multinom(formula = Type~.,data = glass.train)
pred<-predict(mod,glass.test[,-k])
pred
mean(pred==glass.test$Type)
