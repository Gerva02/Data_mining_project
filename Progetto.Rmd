---
title: "Progetto "
author: "Simone Gervasoni Angelo Cardinale Riccardo Bonamoni "
date: "2024-04-05"
output:output: 
  html_document:
    self_contained : TRUE
    toc : TRUE
    toc_depth: 2 
    number_sections: yes
    toc_float: 
      collapsed: no
      smooth_scroll: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)

```

```{r librerie warning=FALSE, message= FALSE }
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
```
# 1) Esploratoria



```{r import e inizio }
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
```





```{r ggcorplots}
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))  
?gg
ggcorrplot(cor(glass%>%
 select(-Type)), lab = T , type = "lower" )
?ggcorrplot
```
#ferro e bario prob da escludere 


```{r barplot}
#questo bar plot è riguardo freq relative
glass %>%
  ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) + 
  geom_bar() 
 
#questo bar plot è riguardo freq assolute
glass %>%
  ggplot(aes(x= Type, y = after_stat(count), fill = Type)) + 
  geom_bar()
```

```{r}
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
  gather(key = Measure, value = value, -Type )  %>%
  ggplot(aes(x = Type, y= value, color = Measure)) +
  geom_violin()+ # possiamo fare il box plot ma è l'unica volta che questo tipo di grafico è utile
  facet_wrap(~ Measure,scales = "free")

```





```{r shapiro test}
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----

# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
  for (j in levels(glass$Type)){
    pvalue_shapiro[i,j]<-
      shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
    # pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
  }
}

round(pvalue_shapiro, 5)

?shapiro.test
```


# 2) preprocessing

```{r division dataset}
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.8) {
  id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
  train <- D1[id,]
  test <- D1[-id,]
  out <- list(train = train, test = test)
}

#Qua abbiamo diviso magari dobbiamo normalizzare 
glass.train <- dataset_division(glass)$train
glass.test <- dataset_division(glass)$test 

#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)

```




# metodi di classificazione




## Alberi
```{r alberi}
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziamo)
tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
mean(tree.pred == glass.test$Type) 
```
vediamo split innutili 
```{r cross validation tree}
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
?cv.tree
```
vediamo che con 11 leaf node è quello che predice meglio

```{r testing cross validation tree}
best.tree <-  prune.misclass(tree.glass , best = 11)
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type) 
```
5% improvement

```{r}
plot(best.tree); text(best.tree,,pretty=0)
```
# KNN 

```{r normalizing}

```





