---
title: "Progetto "
author: "Simone Gervasoni Angelo Cardinale Riccardo Bonamoni "
date: "2024-04-05"
output:
  html_document:
    self_contained : TRUE
    toc : TRUE
    toc_depth: 2 
    number_sections: yes
    toc_float: 
      collapsed: no
      smooth_scroll: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)
```

```{r librerie, warning=FALSE, message= FALSE }
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
```
# Esploratoria



```{r import e inizio }
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
```





```{r ggcorplots}
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))  
ggcorrplot(cor(glass%>%
 select(-Type)), lab = T , type = "lower" )
```
CA e RI sono estremamente correlati per alberi non fa niente ma per Knn andrà vista 


```{r barplot}
#questo bar plot è riguardo freq relative
glass %>%
  ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) + 
  geom_bar() 
 
#questo bar plot è riguardo freq assolute
glass %>%
  ggplot(aes(x= Type, y = after_stat(count), fill = Type)) + 
  geom_bar()
```
probabilmente c'è da trattare problema di dati sbilanciati con smote per 3 5 e 6 



```{r}
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
  gather(key = Measure, value = value, -Type )  %>%
  ggplot(aes(x = Type, y= value, color = Measure)) +
  geom_violin()+ # possiamo fare il box plot ma è l'unica volta che questo tipo di grafico è utile
  facet_wrap(~ Measure,scales = "free")

```
Questo grafico ci riesce a far capire 3 cose : 
1) la varianza e la scale dei vari materiali è diversa tra loro  ( ci porta a fare normalizzazione per knn)
2) la varianza tra diversi type per uno stesso elemento chimico è diversa ( LDA rifiutata )
3) la distribuzione condizionata per ogni elemento chimico (non è quasi mai normale) (Analisi discriminante rifiutata (LDA e QDA)) è estremamente assimetrica 

vediamo inoltre che per type = 6 BA FE K non variano assolutamente ( magari fare un altro grafico) 
```{r}

glass %>%
  filter(Type == "6")
```



```{r shapiro test}
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----

# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
  for (j in levels(glass$Type)){
    pvalue_shapiro[i,j]<-
      shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
    # pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
  }
}

pvalue_shapiro["Ca", "6" ] <- pvalue_shapiro["K", "6" ] <- pvalue_shapiro["Fe", "6" ] <- NA

round(pvalue_shapiro, 5)
```


## preprocessing

```{r division dataset}
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.7) {
  id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
  train <- D1[id,]
  test <- D1[-id,]
  out <- list(train = train, test = test)
}

#Qua abbiamo diviso magari dobbiamo normalizzare 
glass.train <- dataset_division(glass)$train
glass.test <- dataset_division(glass)$test 

#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)

```




## Metodi di classificazione




## Alberi
```{r alberi}
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziamo)
tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
mean(tree.pred == glass.test$Type) 
```
vediamo split innutili 
```{r cross validation tree}
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
```
vediamo che con 11 leaf node è quello che predice meglio

```{r testing cross validation tree}
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type) 
```
5% improvement , but we can see that we have very little data for example class 6 has only 1 data point in test

```{r}
plot(best.tree); text(best.tree,,pretty=0)
```
# KNN 

```{r normalizing}
normalize <- function(x, v = NA) {
  if (is.na(v)){
    return((x - min(x)) / (max(x) - min(x)))
  }
  else{
    return((x - v[1]) / (v[2] -v[1]))
  }
      
}


norm_glass <- glass.train
min_max_matrix <- matrix(rep(NA, 18), nrow= 2 , ncol = (ncol(glass)-1) )
for (i in 1: (ncol(glass)-1)){
  min_max_matrix[1 , i] <- min(norm_glass %>% pull(i))
  min_max_matrix[2 , i] <- max(norm_glass %>% pull(i))
  norm_glass[,i] <- normalize(norm_glass %>% pull(i))
}
```


```{r}

```



