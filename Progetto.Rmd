---
title: "Progetto "
author: "Simone Gervasoni Angelo Cardinale Riccardo Bonamoni "
date: "2024-04-05"
output:
  html_document:
    self_contained : TRUE
    toc : TRUE
    toc_depth: 2 
    number_sections: yes
    toc_float: 
      collapsed: no
      smooth_scroll: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(comment = NA)
```

```{r librerie, warning=FALSE, message= FALSE }
library(tidyverse)
library(mclust)
library(Rmixmod)
library(GGally)
library(caret)
library("tree")
library(ggcorrplot)
library(class)
#library(knnGarden)
```
# Analisi esplorativa



```{r import e inizio }
path <- "glass.csv"
glass <- tibble(read.table(path , sep = "," , header = T))
glass$Type <- factor(glass$Type)
```





```{r ggcorplots}
# glass%>%
#   select(-Type) %>%
#   ggpairs(mapping = aes(color = glass$Type))  
ggcorrplot(cor(glass%>%
 select(-Type)), lab = T , type = "lower" )
```
CA e RI sono estremamente correlati per alberi non fa niente ma per Knn andrà vista 


```{r barplot}
#questo bar plot è riguardo freq relative
glass %>%
  ggplot(aes(x= Type, y = after_stat(count)/sum(after_stat(count)), fill = Type)) + 
  geom_bar() 
 
#questo bar plot è riguardo freq assolute
glass %>%
  ggplot(aes(x= Type, y = after_stat(count), fill = Type)) + 
  geom_bar()
```
probabilmente c'è da trattare problema di dati sbilanciati con smote per 3 5 e 6 



```{r}
#qua devo ancora capire come farlo meglio sarebbero i box plot condizionati e ad ogni misurazione ad ogni tipo il problema è la scala di gradezza è diversa per ogni casella
glass %>%
  gather(key = Measure, value = value, -Type )  %>%
  ggplot(aes(x = Type, y= value, color = Measure)) +
  geom_violin(trim = F)+ 
  geom_boxplot(width=0.1) + 
  facet_wrap( ~ Measure ,scales = "free", ncol =2) 

```
Questo grafico ci riesce a far capire 3 cose : 
1) la varianza e la scale dei vari materiali è diversa tra loro  ( ci porta a fare normalizzazione per knn)
2) la varianza tra diversi type per uno stesso elemento chimico è diversa ( LDA rifiutata )
3) la distribuzione condizionata per ogni elemento chimico (non è quasi mai normale) (Analisi discriminante rifiutata (LDA e QDA)) è estremamente assimetrica 

vediamo inoltre che per type = 6 BA FE K non variano assolutamente ( magari fare un altro grafico) 
```{r}
glass %>%
  filter(Type == "6")
```



```{r shapiro test}
#qua si crea tabella pvalues
pvalue_shapiro <- matrix(0, nrow = (dim(glass)[2]-1), ncol = 6)
rownames(pvalue_shapiro) = colnames(glass)[-10]
colnames(pvalue_shapiro) = levels(glass$Type)
#-----

# Test Shapiro e costruzione di una matrice riassuntiva con i p-value condizionati alla classe
for (i in colnames(glass)[-10]){
  for (j in levels(glass$Type)){
    pvalue_shapiro[i,j]<-
      shapiro.test( jitter(glass %>% filter(Type == j)%>%pull(i)) )$p.value #qua si assegnano tutti i valori, bisonga stare attenti perchè alcuni di questi non sono validi perchè ho messo jitter non lo fa andare in errore quando tutti i valori sono uguali ma introduce noise gaussiano che rende normali quando non sono ugugali
    # pull invece serve per tirare fuori dal tibble un vettore (e non un tibble)
  }
}

pvalue_shapiro["Ca", "6" ] <- pvalue_shapiro["K", "6" ] <- pvalue_shapiro["Fe", "6" ] <- NA

round(pvalue_shapiro, 5)
```


# Preprocessing

```{r division dataset}
#questa è una funzione che divide tra test e train (magari ci serve nel CV)
dataset_division <- function(D1, perc = 0.7) {
  id <- sample(size = round(perc* nrow(D1)) , x = nrow(D1))
  train <- D1[id,]
  test <- D1[-id,]
  out <- list(train = train, test = test)
}

#Qua abbiamo diviso magari dobbiamo normalizzare 
set.seed(123)
glass.train <- dataset_division(glass)$train
glass.test <- dataset_division(glass)$test 

#non trovo il comando per farlo per tutto il data set senza usare apply (dovremmo fare un apply)
# ma inoltre per ogni colonna (se normalizziamo) dobbiamo salvare min e max (e dopo veranno applicati sul test)

```




# Metodi di classificazione




## Alberi
```{r alberi}
#qua ho fatto un albero e sembra buono (migliorerà soltanto se normalizziam
set.seed(123)

tree.glass <- tree(Type ~. , glass.train)
summary(tree.glass)
#plot(tree.glass); text(tree.glass, , pretty = 0) # albero completo # queste due linee vanno eseguite insieme
tree.pred <- predict(tree.glass , glass.test[-10] , type = "class")
#mean(tree.pred == glass.test$Type) 
```
vediamo split inutili 
```{r cross validation tree}
set.seed (7)
cv.tree.glass <- cv.tree(tree.glass , FUN = prune.misclass)
par(mfrow = c(1, 2))
plot(cv.tree.glass$size , cv.tree.glass$dev, type = "b")
points(cv.tree.glass$size[which.min(cv.tree.glass$dev)], cv.tree.glass$dev[which.min(cv.tree.glass$dev)], col = "red", pch = 19)
plot(cv.tree.glass$k, cv.tree.glass$dev, type = "b")
```
vediamo che con 11 leaf node è quello che predice meglio

```{r testing cross validation tree}
best.tree <-  prune.misclass(tree.glass , best = cv.tree.glass$size[which.min(cv.tree.glass$dev)])
tree.pred <- predict(best.tree , glass.test[-10] , type = "class")
confusionMatrix(tree.pred,glass.test$Type )
mean(tree.pred == glass.test$Type) 
```
5% improvement , but we can see that we have very little data for example class 6 has only 1 data point in test

```{r}
plot(best.tree); text(best.tree,,pretty=0)
```

## Alberi 2

```{r }
train_norm<-glass.train
test_norm<-glass.test

tree.best.glass <- tree(Type ~. , glass.train)
pruned.tree.k <-prune.tree(tree.best.glass  ,method="misclass")$k
```

## KNN 

```{r}
# #esiste anche knn.cv !!!!!!!!!
# Kmax<-20
# knn.pred.k<-rep(0,Kmax)
# X_train<-norm_glass %>% select(-Type)
# labels<-norm_glass$Type #qua ho cambiato e non sembra essere cambiato nulla 
# X_test<-norm_glass_test
# for (i in 1:Kmax){
#   set.seed(42)
#   knn.pred <- knn(train=X_train, test=X_test, cl=labels, k = i)
#   knn.pred.k[i]<-mean(knn.pred == glass.test$Type)
# }
# r<-rep("black",Kmax)
# r[which.max(knn.pred.k)]<-"red"
# plot(1:Kmax,knn.pred.k,type="h",ylim=c(0,1),col=r)
# abline(h=max(knn.pred.k),col="purple") #mi sa che ho rotto qualcosa ma è un po' incoprensibile che cosa
```


```{r}
#v è un vettore colonna il primo valore è il minimo il secondo il massimo e il resto solo i valori effettivi delle colonne (Fe, Ba, etc)

#funzione che prende vettore, toglie il primo numero, e lo divide da secondo - primo 


func<-function(v){
  return((v-v[1])/(v[2]-v[1])) # non aggiorno v[1] v[2] fino alla fine e quelli saranno innutili
}
prova <-c(1,2,rnorm(100))
func(prova) #vediamo v[1] -> 0 v[2]->1

# matrix sarà la nostra tabella min e max
norm_aux<-function(data,matrix){
  data_2<-rbind(matrix,data)  
  data_norm<-apply(data_2,MARGIN = 2,func) #applichiamo func ad ogni colonna func
  return(data_norm[3:nrow(data_norm),]) # da 3 in poi perchè i primi due valori sono innutili 
}

# questa funzione prende sia il train che il test e normalizza il test con min e max del train
normalize_2<-function(train,test){
  matrix_min_max<-rbind(apply(train,MARGIN = 2,min),apply(train,MARGIN = 2,max)) #qua salviamo min e max -> matrice che anda in norm aux
  train_norm<-norm_aux(train,matrix_min_max)
  test_norm<-norm_aux(test,matrix_min_max)
  return(list(train_norm=train_norm,test_norm=test_norm))
} 

out<-normalize_2(glass.train[,-ncol(glass.train)],glass.test[,-ncol(glass.test)])
out$train_norm[1:10,]
out$test_norm[1:10,]
#mi viene da piangere, ha runnato tutto senza bug
#gervi fai un check che poi possiamo usarla
```
##Confronto metodi


```{r}
cv<-5
p<-1-1/cv
n.train<-nrow(glass.train)
k.train <-ncol(glass.train)
labels_train <-glass.train$Type
knn.kmax<-10
tree.size.max<- length(pruned.tree.k)-2
mat<-as.data.frame(matrix(NA,nrow=(knn.kmax+tree.size.max),ncol=cv+2))
mat[1:knn.kmax,1]<-"knn"
mat[(knn.kmax+1):(knn.kmax+tree.size.max),1]<-"tree"
mat[1:knn.kmax,2]<-1:knn.kmax
mat[(knn.kmax+1):(knn.kmax+tree.size.max),2]<-1:tree.size.max

#loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv
for (j in 1:cv){
  split<-sample(rep(c(1:5),n.train/cv), size=n.train) # facciamo così con il rep per evitare gruppi sbilanciati n.train/cv deve fare un numero intero
  out_norm_cv<-normalize_2(glass.train[split != j  ,-k.train] ,glass.train[split ==j ,-k.train])
  train_cv<-out_norm_cv$train_norm
  test_cv<-out_norm_cv$test_norm
  #metodo knn
  for (i in 1:knn.kmax){
    set.seed(42)
    knn.pred <- knn(train=train_cv, test=test_cv, cl=labels_train[split != j], k = i)
    #knn.pred <- knnMCN(train=train_cv, test=test_cv, TstX = NULL, K = i, ShowObs = F) 
    #TENIAMO PRESENTE CHE FACENDO NORMALIZE IN QUESTO MODO IL     RUSLTATO CAMBIA TOTALMENTE E PASSA DA k=1 a k=4 CHE HA SENSO??? O FORSE CAMBIO DRASTICO...NORMALIZZARE COME AVEVO FATTO PRIMA       ERA SBAGLIATO E QUESTO MIGLIORAMENTO LO ATTESTA (CON E SENZA NORMALIZZAZIONE C'E UN CAMBIAMENTO BELLO STRONG). RAZIONALE CHE        USCISSE CON k=1 CHE QUINDI PROBABILMENTE ERA UNA E UNA SOLA VARIABILE DELL'UNICO PUNTO VICINO A FARE LA DIFFERENZA
    mat[i,j+2]<-mean(knn.pred == labels_train[split ==j])
  }
    
  
  train.cv.tree <- glass.train[split != j  ,-k.train] 
  test.cv.tree  <-glass.train[split ==j ,-k.train]
  train.cv.tree$Type <-labels_train[split != j]
  test.cv.tree$Type <-labels_train[split ==j]
  tree.glass.cv <- tree(Type ~. , train.cv.tree)
  #metodo alberi
  for (i in 1:tree.size.max){
    set.seed(42)
    pruned.tree <-prune.tree(tree.glass ,method="misclass", k= pruned.tree.k[i+1] )
    k <- pruned.tree.k[i+1]
    tree.pred <-predict(pruned.tree , test.cv.tree[-10] , type = "class")
    mat[knn.kmax+i,j+2]<- mean(tree.pred == labels_train[split ==j])
  }
}
res<-cbind(mat[,c(1,2)],apply(mat[,3:j+2],MARGIN=1,mean)) #possiamo usare median se vogliamo
colnames(res)<-c("metodo","hyperparameter","accuracy")
res

```

loop più grande è quello del cv per ogni split del cv si allenano tutti i modelli con tutti gli iperparametri diversi si calcola l'errore e si passa al prossimo blocco di cv



# Test e conclusioni

```{r}
out_norm<- normalize_2(glass.train[,-k.train],glass.test[,-k.train])
train_norm<-out_norm$train_norm
test_norm<-out_norm$test_norm


knn.pred <- knn(train=train_norm, test=test_norm, cl=labels_train, k = 2)
mean(glass.test$Type == knn.pred)
```


```{r}
pruned.tree.k[2]



```

